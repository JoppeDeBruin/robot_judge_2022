{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW06: ML and Causal Inference (due November 9th)\n",
    "\n",
    "**As a first part of THIS WEEK'S homework (HW06) you will have to provide feedback to two of your classmates' essays on Eduflow.** On Eduflow, you will be automatically assigned to the two essays you have to provide feedback to on Friday, in case you want to start ahead.\n",
    "\n",
    "### For the coding part of the homework, you will have to solve only one of the three exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Double Machine learning with XGboost\n",
    "\n",
    "In this exercise you will investigate a research question similar to the one in HW02. Namely, what is the effect of being in a Union on wages? You will use the same data as in HW02 (description of the variables can be found [here](https://rdrr.io/rforge/sampleSelection/man/nlswork.html)). Although, here instead of just including controls, you will estimate the effect of union membership on wages using double machine learning and you will use XGboost as machine learning algorithm. The regression of reference is the following: \n",
    "\n",
    "<center> $ln\\_wage_i = \\beta_0 + \\beta_1 union_i +\\varepsilon_i$ </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data (NLSY)\n",
    "import pandas as pd\n",
    "df = pd.read_stata('http://www.stata-press.com/data/r16/nlswork.dta')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['idcode', 'year', 'birth_yr', 'age', 'race', 'msp', 'nev_mar', 'grade',\n",
       "       'collgrad', 'not_smsa', 'c_city', 'south', 'ind_code', 'occ_code',\n",
       "       'union', 'wks_ue', 'ttl_exp', 'tenure', 'hours', 'wks_work', 'ln_wage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Y = df['ln_wage']\n",
    "D = df['union']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>ln_wage</td>     <th>  R-squared:         </th> <td>   0.052</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.052</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   741.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 07 Nov 2022</td> <th>  Prob (F-statistic):</th> <td>4.56e-159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:43:06</td>     <th>  Log-Likelihood:    </th> <td> -8266.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 13452</td>      <th>  AIC:               </th> <td>1.654e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 13450</td>      <th>  BIC:               </th> <td>1.655e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    1.6564</td> <td>    0.004</td> <td>  377.147</td> <td> 0.000</td> <td>    1.648</td> <td>    1.665</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>union</th>     <td>    0.2502</td> <td>    0.009</td> <td>   27.238</td> <td> 0.000</td> <td>    0.232</td> <td>    0.268</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>425.572</td> <th>  Durbin-Watson:     </th> <td>   1.032</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 895.660</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.205</td>  <th>  Prob(JB):          </th> <td>3.24e-195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.196</td>  <th>  Cond. No.          </th> <td>    2.53</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                ln_wage   R-squared:                       0.052\n",
       "Model:                            OLS   Adj. R-squared:                  0.052\n",
       "Method:                 Least Squares   F-statistic:                     741.9\n",
       "Date:                Mon, 07 Nov 2022   Prob (F-statistic):          4.56e-159\n",
       "Time:                        14:43:06   Log-Likelihood:                -8266.7\n",
       "No. Observations:               13452   AIC:                         1.654e+04\n",
       "Df Residuals:                   13450   BIC:                         1.655e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      1.6564      0.004    377.147      0.000       1.648       1.665\n",
       "union          0.2502      0.009     27.238      0.000       0.232       0.268\n",
       "==============================================================================\n",
       "Omnibus:                      425.572   Durbin-Watson:                   1.032\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              895.660\n",
       "Skew:                           0.205   Prob(JB):                    3.24e-195\n",
       "Kurtosis:                       4.196   Cond. No.                         2.53\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "## Run the regression written above\n",
    "res = smf.ols(\"ln_wage ~ union\", data = df ).fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What could be potential sources of bias (i.e. confounders)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joppe\\AppData\\Local\\Temp/ipykernel_29216/3920582546.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[cat_vars] = encoder.fit_transform(X[cat_vars])\n"
     ]
    }
   ],
   "source": [
    "# fill in X with all predictors that are not colliders\n",
    "X = df[['age', 'year', 'collgrad', 'race', 'msp', 'not_smsa', \"c_city\", \"south\"]]\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "cat_vars = [\"race\", \"not_smsa\"]\n",
    "X[cat_vars] = encoder.fit_transform(X[cat_vars])\n",
    "#df2[cont_vars] = df2[cont_vars].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         float64\n",
       "year           int8\n",
       "collgrad       int8\n",
       "race        float64\n",
       "msp         float64\n",
       "not_smsa    float64\n",
       "c_city      float64\n",
       "south       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (f1_score, mean_squared_error)\n",
    "# split into sample A and sample B\n",
    "X_A, X_B, D_A, D_B, Y_A, Y_B = train_test_split(X, D ,Y, test_size = 0.5, random_state = 123)\n",
    "\n",
    "\n",
    "# Within each sample, make a validation set for xgboost early stopping\n",
    "X_A_train, X_A_val, D_A_train, D_A_val, Y_A_train, Y_A_val = train_test_split(X_A, D_A, Y_A, test_size = 0.2, random_state = 123)\n",
    "X_B_train, X_B_val, D_B_train, D_B_val, Y_B_train, Y_B_val = train_test_split(X_B, D_B, Y_B, test_size = 0.2, random_state = 123)\n",
    "\n",
    "eval_set_A_Y = [(X_A_val, Y_A_val)]\n",
    "eval_set_B_Y = [(X_B_val, Y_B_val)]\n",
    "\n",
    "eval_set_A_D = [(X_A_val, D_A_val)]\n",
    "eval_set_B_D = [(X_B_val, D_B_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.95466\n",
      "[1]\tvalidation_0-rmse:0.72517\n",
      "[2]\tvalidation_0-rmse:0.58049\n",
      "[3]\tvalidation_0-rmse:0.49391\n",
      "[4]\tvalidation_0-rmse:0.44447\n",
      "[5]\tvalidation_0-rmse:0.41859\n",
      "[6]\tvalidation_0-rmse:0.40576\n",
      "[7]\tvalidation_0-rmse:0.39887\n",
      "[8]\tvalidation_0-rmse:0.39582\n",
      "[9]\tvalidation_0-rmse:0.39411\n",
      "[10]\tvalidation_0-rmse:0.39315\n",
      "[11]\tvalidation_0-rmse:0.39278\n",
      "[12]\tvalidation_0-rmse:0.39308\n",
      "[13]\tvalidation_0-rmse:0.39303\n",
      "[14]\tvalidation_0-rmse:0.39345\n",
      "[15]\tvalidation_0-rmse:0.39408\n",
      "[16]\tvalidation_0-rmse:0.39445\n",
      "[17]\tvalidation_0-rmse:0.39485\n",
      "[18]\tvalidation_0-rmse:0.39467\n",
      "[19]\tvalidation_0-rmse:0.39492\n",
      "[20]\tvalidation_0-rmse:0.39502\n",
      "[21]\tvalidation_0-rmse:0.39619\n",
      "[22]\tvalidation_0-rmse:0.39626\n",
      "[23]\tvalidation_0-rmse:0.39658\n",
      "[24]\tvalidation_0-rmse:0.39675\n",
      "[25]\tvalidation_0-rmse:0.39705\n",
      "[26]\tvalidation_0-rmse:0.39766\n",
      "[27]\tvalidation_0-rmse:0.39776\n",
      "[28]\tvalidation_0-rmse:0.39779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joppe\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29]\tvalidation_0-rmse:0.39797\n",
      "[30]\tvalidation_0-rmse:0.39796\n",
      "[0]\tvalidation_0-rmse:0.95057\n",
      "[1]\tvalidation_0-rmse:0.72435\n",
      "[2]\tvalidation_0-rmse:0.58136\n",
      "[3]\tvalidation_0-rmse:0.49627\n",
      "[4]\tvalidation_0-rmse:0.44913\n",
      "[5]\tvalidation_0-rmse:0.42299\n",
      "[6]\tvalidation_0-rmse:0.40939\n",
      "[7]\tvalidation_0-rmse:0.40292\n",
      "[8]\tvalidation_0-rmse:0.39882\n",
      "[9]\tvalidation_0-rmse:0.39724\n",
      "[10]\tvalidation_0-rmse:0.39636\n",
      "[11]\tvalidation_0-rmse:0.39576\n",
      "[12]\tvalidation_0-rmse:0.39531\n",
      "[13]\tvalidation_0-rmse:0.39593\n",
      "[14]\tvalidation_0-rmse:0.39666\n",
      "[15]\tvalidation_0-rmse:0.39639\n",
      "[16]\tvalidation_0-rmse:0.39709\n",
      "[17]\tvalidation_0-rmse:0.39726\n",
      "[18]\tvalidation_0-rmse:0.39783\n",
      "[19]\tvalidation_0-rmse:0.39782\n",
      "[20]\tvalidation_0-rmse:0.39857\n",
      "[21]\tvalidation_0-rmse:0.39917\n",
      "[22]\tvalidation_0-rmse:0.39965\n",
      "RMSE on Test Set\n",
      "Sample A: 0.392779\n",
      "Sample B: 0.395315\n"
     ]
    }
   ],
   "source": [
    "# Step 1. In both samples, train an xgboost regressor model to predict log wages (outcome Y)\n",
    "# use early stopping.\n",
    "from xgboost import XGBRegressor\n",
    "xgbr_a = XGBRegressor()\n",
    "xgbr_b = XGBRegressor()\n",
    "\n",
    "xgbr_a.fit(X_A_train, Y_A_train, early_stopping_rounds = 20, eval_set = eval_set_A_Y, verbose = True)\n",
    "xgbr_b.fit(X_B_train, Y_B_train, early_stopping_rounds = 10, eval_set = eval_set_B_Y, verbose = True)\n",
    "\n",
    "\n",
    "print('RMSE on Test Set')\n",
    "print('Sample A: %f' % np.sqrt(mean_squared_error(xgbr_a.predict(X_A_val), Y_A_val)))\n",
    "print('Sample B: %f' % np.sqrt(mean_squared_error(xgbr_b.predict(X_B_val), Y_B_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.60743\n",
      "[1]\tvalidation_0-logloss:0.56783\n",
      "[2]\tvalidation_0-logloss:0.55015\n",
      "[3]\tvalidation_0-logloss:0.54025\n",
      "[4]\tvalidation_0-logloss:0.53795\n",
      "[5]\tvalidation_0-logloss:0.53797\n",
      "[6]\tvalidation_0-logloss:0.54117\n",
      "[7]\tvalidation_0-logloss:0.54377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joppe\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\tvalidation_0-logloss:0.54657\n",
      "[9]\tvalidation_0-logloss:0.55178\n",
      "[10]\tvalidation_0-logloss:0.55582\n",
      "[11]\tvalidation_0-logloss:0.56160\n",
      "[12]\tvalidation_0-logloss:0.56860\n",
      "[13]\tvalidation_0-logloss:0.57379\n",
      "[0]\tvalidation_0-logloss:0.61791\n",
      "[1]\tvalidation_0-logloss:0.58093\n",
      "[2]\tvalidation_0-logloss:0.56488\n",
      "[3]\tvalidation_0-logloss:0.55580\n",
      "[4]\tvalidation_0-logloss:0.55234\n",
      "[5]\tvalidation_0-logloss:0.55487\n",
      "[6]\tvalidation_0-logloss:0.55938\n",
      "[7]\tvalidation_0-logloss:0.56460\n",
      "[8]\tvalidation_0-logloss:0.57145\n",
      "[9]\tvalidation_0-logloss:0.57735\n",
      "[10]\tvalidation_0-logloss:0.58198\n",
      "[11]\tvalidation_0-logloss:0.58831\n",
      "[12]\tvalidation_0-logloss:0.59386\n",
      "[13]\tvalidation_0-logloss:0.59960\n",
      "[14]\tvalidation_0-logloss:0.60521\n",
      "F1 Score on Test Set\n",
      "Sample A: 0.215962\n",
      "Sample B: 0.213636\n"
     ]
    }
   ],
   "source": [
    "# Step 2. In both samples, train an xgboost classifier model to predict union status (treatment D)\n",
    "# use early stopping.\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgbc_a = XGBClassifier(n_estimators = 100, alpha = 0.01, max_depth =20, learning_rate = 0.3)\n",
    "xgbc_b = XGBClassifier(n_estimators = 100, alpha = 0.01, max_depth = 20, learning_rate = 0.3)\n",
    "\n",
    "xgbc_a.fit(X_A_train, D_A_train, early_stopping_rounds = 10, eval_set = eval_set_A_D, verbose = True)\n",
    "xgbc_b.fit(X_B_train, D_B_train, early_stopping_rounds = 10, eval_set = eval_set_B_D, verbose = True)\n",
    "\n",
    "\n",
    "\n",
    "print('F1 Score on Test Set')\n",
    "print('Sample A: %f' % f1_score(xgbc_a.predict(X_A_val), D_A_val))\n",
    "print('Sample B: %f' % f1_score(xgbc_b.predict(X_B_val), D_B_val))\n",
    "\n",
    "# Unfortunately, the classification does not work very well, as seen from the F1 scores. With tweaking of the hyperparmaters\n",
    "# not cross validated, but based on the validation set, we can get somewhat better performance, but still pretty poor..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. Cross-fitting: Form predictions in other sample.\n",
    "\n",
    "# predict wages in sample A using model trained in sample B:\n",
    "Y_hat_A = xgbr_b.predict(X_A)\n",
    "\n",
    "# vice versa:\n",
    "Y_hat_B = xgbr_a.predict(X_B)\n",
    "    \n",
    "# predict union status in sample A using model trained in sample B:\n",
    "D_hat_A = xgbc_b.predict(X_A)\n",
    "    \n",
    "# vice versa:\n",
    "D_hat_B = xgbc_a.predict(X_B)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that residuals for a variable $Z_i$ are computed as follows:\n",
    "\n",
    "<center>$\\tilde{Z}_i = Z_i - \\hat{Z}_i$</center>\n",
    "\n",
    "where $\\hat{Z}_i$ is the predicted value of $Z_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute residuals for wages and union status.\n",
    "\n",
    "# residualized wages in samples A and B:\n",
    "Y_tilde_A =  Y_A - Y_hat_A\n",
    "Y_tilde_B =  Y_B - Y_hat_B\n",
    "\n",
    "# residualized union status in samples A and B:\n",
    "D_tilde_A =  D_A - D_hat_A#TODO\n",
    "D_tilde_B =  D_B - D_hat_B#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "union    0.14345\n",
      "dtype: float64\n",
      "union    0.009681\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Step 4. Run OLS regressions of the residualized variables and produce Double ML estimate\n",
    "## use robust standard errors \n",
    "import statsmodels.regression.linear_model as smf\n",
    "\n",
    "res_A = smf.OLS(Y_tilde_A, D_tilde_A).fit(cov_type = \"hc1\")\n",
    "beta_A = res_A.params\n",
    "se_A = res_A.bse\n",
    "\n",
    "res_B = smf.OLS(Y_tilde_B, D_tilde_B).fit(cov_type = \"hc1\")\n",
    "beta_B = res_B.params\n",
    "se_B = res_B.bse\n",
    "\n",
    "##Take the average of the two coefficient and standard errors and show the result\n",
    "\n",
    "beta_average = (beta_A + beta_B)/2\n",
    "print(beta_average)\n",
    "\n",
    "se_average = (se_A + se_B)/2\n",
    "print(se_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "union    0.130426\n",
       "dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare the estimates form this and the previous regression. How do these change?**\n",
    "\n",
    "When we compare the average value of the coefficient in the double ML approach to the normal OLS estimate, we see that it is smaller (0.14 vs 0.25). In general, we know that the estimate for beta in the normal OLS specification is biased. Now, we see that if we correct for this bias, using double ML, that the estimate for beta is indeed different. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpret the coefficient from the double ml approach. Can it be interpreted as causal?**\n",
    "\n",
    "This coefficient can be interpreted as causal as long as our adjusting for covariates covers all relevant confounders. IF that is the case, then we can interpret beta as the causal effect. This is similar to what we discussed for regular adjusting for confounders. However, now we do it in a non-linear way, instead of linearly adjustment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Synthetic Control Method\n",
    "\n",
    "In this exercise we will investigate the economic effects of conflict by focusing on the Basque Country. In particular, we will focus on terrorist conflicts in late 1960's in this area and use as comparison group all other regions of Spain that did not experience terrorism. The (raw) reference regression is the following:\n",
    "\n",
    "<center>$gdpcap_r = \\beta_0 + \\beta_1 terrorism_r + \\varepsilon_r$</center>\n",
    "\n",
    "where $gdpcap_r$ is GDP per capita in region $r$ and $terrorism_r$ is a dummy equal to 1 if terrorist conflict happened in that region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##note that to work correctly you will also have to downgrade scipy to version 1.4.1\n",
    "!pip install scipy==1.4.1\n",
    "!pip install SyntheticControlMethods\n",
    "\n",
    "#restart the kernel after downrgading scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regionname</th>\n",
       "      <th>year</th>\n",
       "      <th>gdpcap</th>\n",
       "      <th>sec.agriculture</th>\n",
       "      <th>sec.energy</th>\n",
       "      <th>sec.industry</th>\n",
       "      <th>sec.construction</th>\n",
       "      <th>sec.services.venta</th>\n",
       "      <th>sec.services.nonventa</th>\n",
       "      <th>school.illit</th>\n",
       "      <th>school.prim</th>\n",
       "      <th>school.med</th>\n",
       "      <th>school.high</th>\n",
       "      <th>school.post.high</th>\n",
       "      <th>popdens</th>\n",
       "      <th>invest</th>\n",
       "      <th>terrorism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Andalucia</td>\n",
       "      <td>1955</td>\n",
       "      <td>1.688732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Andalucia</td>\n",
       "      <td>1956</td>\n",
       "      <td>1.758498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Andalucia</td>\n",
       "      <td>1957</td>\n",
       "      <td>1.827621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Andalucia</td>\n",
       "      <td>1958</td>\n",
       "      <td>1.852756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Andalucia</td>\n",
       "      <td>1959</td>\n",
       "      <td>1.878035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   regionname  year    gdpcap  sec.agriculture  sec.energy  sec.industry  \\\n",
       "43  Andalucia  1955  1.688732              NaN         NaN           NaN   \n",
       "44  Andalucia  1956  1.758498              NaN         NaN           NaN   \n",
       "45  Andalucia  1957  1.827621              NaN         NaN           NaN   \n",
       "46  Andalucia  1958  1.852756              NaN         NaN           NaN   \n",
       "47  Andalucia  1959  1.878035              NaN         NaN           NaN   \n",
       "\n",
       "    sec.construction  sec.services.venta  sec.services.nonventa  school.illit  \\\n",
       "43               NaN                 NaN                    NaN           NaN   \n",
       "44               NaN                 NaN                    NaN           NaN   \n",
       "45               NaN                 NaN                    NaN           NaN   \n",
       "46               NaN                 NaN                    NaN           NaN   \n",
       "47               NaN                 NaN                    NaN           NaN   \n",
       "\n",
       "    school.prim  school.med  school.high  school.post.high  popdens  invest  \\\n",
       "43          NaN         NaN          NaN               NaN      NaN     NaN   \n",
       "44          NaN         NaN          NaN               NaN      NaN     NaN   \n",
       "45          NaN         NaN          NaN               NaN      NaN     NaN   \n",
       "46          NaN         NaN          NaN               NaN      NaN     NaN   \n",
       "47          NaN         NaN          NaN               NaN      NaN     NaN   \n",
       "\n",
       "    terrorism  \n",
       "43          0  \n",
       "44          0  \n",
       "45          0  \n",
       "46          0  \n",
       "47          0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "df = pd.read_csv('data/HW06_data_scm.csv')\n",
    "del df['Unnamed: 0']\n",
    "del df['regionno']\n",
    "df = df.loc[df[\"regionname\"] != \"Spain (Espana)\"] \n",
    "\n",
    "df['terrorism'] = df['regionname']=='Basque Country (Pais Vasco)'\n",
    "df['terrorism'] = df['terrorism'].astype('int')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "##plot gdp per capita over time separately for basque country and other regions of spain\n",
    "## (i.e., separately for terrorism == 1 or 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Does the parallel trend assumption hold? If not, why do you think this is the case?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run a regression of terrorism on gdp per capita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What could be potential threats to a causal interpretation of this result?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SyntheticControlMethods import Synth, DiffSynth\n",
    "del df['terrorism']\n",
    "\n",
    "##fit the synthetic control \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##visualize the plot \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What can you conclude about the effect of conflict on GDP?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show which spanish regions were used to create the synthetic control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Heterogenous Treatment Effects\n",
    "\n",
    "In this exercise we will investigate the effect of case management on mental health outcomes. These data come from a randomized control trial where patients were assigned to *intensive* or *standard* case management. In this context, the treatment is being assigned to the **intensive** case management while patients assigned to the **standard** case management belong to the control group..\n",
    "\n",
    "In this exercise we will focus on heterogenous treatment effects, rather than on isolating the casual effect of the treatment. In particular, we will investigate characteristics of individuals who are most and least responsive to the treatment, i.e., to being assigned to the intensive case management. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trialid': 'Trial ID',\n",
       " 'centreid': 'Trial centre',\n",
       " 'status': 'Patient status at baseline',\n",
       " 'age': 'Age in years at baseline',\n",
       " 'sex': 'Sex',\n",
       " 'afcarib': 'Ethnic group',\n",
       " 'ocfabth': \"Father's social class at birth\",\n",
       " 'chron1l': 'Months since onset of psychosis, logged',\n",
       " 'hos94': 'Days in hospital for psychiatric reasons: 2 years before baseline',\n",
       " 'cprs94': 'Psychopathology at baseline (CPRS)',\n",
       " 'das94': 'Disability at baseline (DAS)',\n",
       " 'sat94': '(Dis)satisfaction with services at baseline',\n",
       " 'rand': 'Randomised group',\n",
       " 'hos96': 'Days in hospital for psychiatric reasons: 2 years after baseline',\n",
       " 'cprs96': 'Psychopathology at 2 years (CPRS)',\n",
       " 'sat96': '(Dis)satisfaction with services at 2 years'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "df = pd.read_stata('http://www.homepages.ucl.ac.uk/~rmjwiww/stata/missing/uk500.dta')\n",
    "df = df.dropna()\n",
    "pd.read_stata('http://www.homepages.ucl.ac.uk/~rmjwiww/stata/missing/uk500.dta', iterator=True).variable_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trialid</th>\n",
       "      <th>centreid</th>\n",
       "      <th>status</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>afcarib</th>\n",
       "      <th>ocfabth</th>\n",
       "      <th>chron1l</th>\n",
       "      <th>hos94</th>\n",
       "      <th>cprs94</th>\n",
       "      <th>das94</th>\n",
       "      <th>sat94</th>\n",
       "      <th>rand</th>\n",
       "      <th>hos96</th>\n",
       "      <th>cprs96</th>\n",
       "      <th>sat96</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107.0</td>\n",
       "      <td>St George's</td>\n",
       "      <td>Out-patient</td>\n",
       "      <td>27.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Other</td>\n",
       "      <td>A</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Intensive case management</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222005.0</td>\n",
       "      <td>St Mary's</td>\n",
       "      <td>In hospital</td>\n",
       "      <td>41.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Other</td>\n",
       "      <td>D</td>\n",
       "      <td>4.521789</td>\n",
       "      <td>240.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Intensive case management</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222018.0</td>\n",
       "      <td>St Mary's</td>\n",
       "      <td>In hospital</td>\n",
       "      <td>25.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Other</td>\n",
       "      <td>C2</td>\n",
       "      <td>4.094345</td>\n",
       "      <td>48.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Intensive case management</td>\n",
       "      <td>263.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>312015.0</td>\n",
       "      <td>King's</td>\n",
       "      <td>Out-patient</td>\n",
       "      <td>31.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Other</td>\n",
       "      <td>A</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>60.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Intensive case management</td>\n",
       "      <td>45.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>221023.0</td>\n",
       "      <td>St Mary's</td>\n",
       "      <td>In hospital</td>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Afro-Caribbean</td>\n",
       "      <td>C2</td>\n",
       "      <td>4.430817</td>\n",
       "      <td>60.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.571428</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Intensive case management</td>\n",
       "      <td>58.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>19.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trialid     centreid       status   age     sex         afcarib ocfabth  \\\n",
       "1     107.0  St George's  Out-patient  27.0    male           Other       A   \n",
       "2  222005.0    St Mary's  In hospital  41.0    male           Other       D   \n",
       "3  222018.0    St Mary's  In hospital  25.0    male           Other      C2   \n",
       "5  312015.0       King's  Out-patient  31.0  female           Other       A   \n",
       "6  221023.0    St Mary's  In hospital  35.0    male  Afro-Caribbean      C2   \n",
       "\n",
       "    chron1l  hos94  cprs94     das94  sat94                       rand  hos96  \\\n",
       "1  3.178054   80.0     4.0  0.285714   18.0  Intensive case management   27.0   \n",
       "2  4.521789  240.0     6.0  0.750000   15.0  Intensive case management   15.0   \n",
       "3  4.094345   48.0    12.0  0.125000   18.0  Intensive case management  263.0   \n",
       "5  4.787492   60.0    28.0  2.375000   20.0  Intensive case management   45.0   \n",
       "6  4.430817   60.0    25.0  1.571428   24.0  Intensive case management   58.0   \n",
       "\n",
       "   cprs96   sat96  \n",
       "1     3.0  22.000  \n",
       "2    13.0   9.000  \n",
       "3     6.0  21.375  \n",
       "5    19.0  17.000  \n",
       "6    27.0  19.125  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The treatment variable is $rand$, the post-treatment outcomes are $hos96$, $cprs96$ and $sat96$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intensive case management    130\n",
       "Standard case management     116\n",
       "Name: rand, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatvar = 'rand'\n",
    "df[treatvar].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sat96</th>\n",
       "      <th>hos96</th>\n",
       "      <th>cprs96</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>246.000000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>246.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.271341</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>17.790587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.723009</td>\n",
       "      <td>104.046722</td>\n",
       "      <td>14.090911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20.187500</td>\n",
       "      <td>93.500000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>692.000000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sat96       hos96      cprs96\n",
       "count  246.000000  246.000000  246.000000\n",
       "mean    17.271341   65.500000   17.790587\n",
       "std      4.723009  104.046722   14.090911\n",
       "min      9.000000    0.000000    0.000000\n",
       "25%     14.000000    0.000000    7.000000\n",
       "50%     17.000000   15.000000   15.000000\n",
       "75%     20.187500   93.500000   26.000000\n",
       "max     32.000000  692.000000   71.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes = ['sat96', 'hos96', 'cprs96']\n",
    "df[outcomes].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to these variables we need a set of covariates that we want to use to identify individuals who are most and least responsive to treatment. We also encode categorical covariates and prepare them for the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>sat94</th>\n",
       "      <th>ocfabth</th>\n",
       "      <th>hos94</th>\n",
       "      <th>das94</th>\n",
       "      <th>cprs94</th>\n",
       "      <th>age</th>\n",
       "      <th>afcarib</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.571428</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   status  sex  sat94  ocfabth  hos94     das94  cprs94   age  afcarib\n",
       "1     1.0  1.0   18.0      0.0   80.0  0.285714     4.0  27.0      1.0\n",
       "2     0.0  1.0   15.0      4.0  240.0  0.750000     6.0  41.0      1.0\n",
       "3     0.0  1.0   18.0      3.0   48.0  0.125000    12.0  25.0      1.0\n",
       "5     1.0  0.0   20.0      0.0   60.0  2.375000    28.0  31.0      1.0\n",
       "6     0.0  1.0   24.0      3.0   60.0  1.571428    25.0  35.0      0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encoding Categorical covariates and preparing the data for tensorflow\n",
    "covariates = ['status', 'sex', 'sat94', 'ocfabth', 'hos94', 'das94', 'cprs94', 'age', 'afcarib']\n",
    "covariates_cat = ['status', 'sex', 'ocfabth', 'afcarib']\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "df[covariates_cat] = encoder.fit_transform(df[covariates_cat])\n",
    "df[covariates] = df[covariates].astype('float32')\n",
    "df[covariates].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the dataset by treatment and control\n",
    "# Within each sample, create a training, a test and a validation set\n",
    "\n",
    "df_treat = #TODO\n",
    "df_control = #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##choose one of the three outcomes to analyze\n",
    "## using xgboost regressor train two model to predict the outcome from the covariates\n",
    "## the first model should be trained on the treated sample, while the second on the control\n",
    "## use early stopping\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "xgbr_treat = XGBRegressor()\n",
    "xgbr_control = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##get predicted outcomes using the combined test sets for both models \n",
    "\n",
    "test_set = Xtreat_test.append(Xcontrol_test) \n",
    "y_hat_treat = ...\n",
    "y_hat_control = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##find the three individuals in the test set that are most and least responsive to the treatment\n",
    "##namely the three individuals for who the treatment effect is larger and those for who it is smaller\n",
    "\n",
    "test_set['treat_effect'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##visualize and comment on the covariates of these individuals "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
